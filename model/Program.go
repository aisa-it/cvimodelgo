// Code generated by the FlatBuffers compiler. DO NOT EDIT.

package model

import (
	flatbuffers "github.com/google/flatbuffers/go"
)

type Program struct {
	_tab flatbuffers.Table
}

func GetRootAsProgram(buf []byte, offset flatbuffers.UOffsetT) *Program {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &Program{}
	x.Init(buf, n+offset)
	return x
}

func FinishProgramBuffer(builder *flatbuffers.Builder, offset flatbuffers.UOffsetT) {
	builder.Finish(offset)
}

func GetSizePrefixedRootAsProgram(buf []byte, offset flatbuffers.UOffsetT) *Program {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &Program{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func FinishSizePrefixedProgramBuffer(builder *flatbuffers.Builder, offset flatbuffers.UOffsetT) {
	builder.FinishSizePrefixed(offset)
}

func (rcv *Program) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *Program) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *Program) BatchNum() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Program) MutateBatchNum(n uint32) bool {
	return rcv._tab.MutateUint32Slot(4, n)
}

func (rcv *Program) NeuronSize() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Program) MutateNeuronSize(n uint32) bool {
	return rcv._tab.MutateUint32Slot(6, n)
}

func (rcv *Program) InputTensors(j int) []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		a := rcv._tab.Vector(o)
		return rcv._tab.ByteVector(a + flatbuffers.UOffsetT(j*4))
	}
	return nil
}

func (rcv *Program) InputTensorsLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *Program) OutputTensors(j int) []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(10))
	if o != 0 {
		a := rcv._tab.Vector(o)
		return rcv._tab.ByteVector(a + flatbuffers.UOffsetT(j*4))
	}
	return nil
}

func (rcv *Program) OutputTensorsLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(10))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *Program) TensorMap(obj *Tensor, j int) bool {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(12))
	if o != 0 {
		x := rcv._tab.Vector(o)
		x += flatbuffers.UOffsetT(j) * 4
		x = rcv._tab.Indirect(x)
		obj.Init(rcv._tab.Bytes, x)
		return true
	}
	return false
}

func (rcv *Program) TensorMapLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(12))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *Program) Routines(obj *Routine, j int) bool {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(14))
	if o != 0 {
		x := rcv._tab.Vector(o)
		x += flatbuffers.UOffsetT(j) * 4
		x = rcv._tab.Indirect(x)
		obj.Init(rcv._tab.Bytes, x)
		return true
	}
	return false
}

func (rcv *Program) RoutinesLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(14))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *Program) SharedGmem() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(16))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Program) MutateSharedGmem(n uint32) bool {
	return rcv._tab.MutateUint32Slot(16, n)
}

func (rcv *Program) PrivateGmem() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(18))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Program) MutatePrivateGmem(n uint32) bool {
	return rcv._tab.MutateUint32Slot(18, n)
}

func ProgramStart(builder *flatbuffers.Builder) {
	builder.StartObject(8)
}
func ProgramAddBatchNum(builder *flatbuffers.Builder, batchNum uint32) {
	builder.PrependUint32Slot(0, batchNum, 0)
}
func ProgramAddNeuronSize(builder *flatbuffers.Builder, neuronSize uint32) {
	builder.PrependUint32Slot(1, neuronSize, 0)
}
func ProgramAddInputTensors(builder *flatbuffers.Builder, inputTensors flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(2, flatbuffers.UOffsetT(inputTensors), 0)
}
func ProgramStartInputTensorsVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func ProgramAddOutputTensors(builder *flatbuffers.Builder, outputTensors flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(3, flatbuffers.UOffsetT(outputTensors), 0)
}
func ProgramStartOutputTensorsVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func ProgramAddTensorMap(builder *flatbuffers.Builder, tensorMap flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(4, flatbuffers.UOffsetT(tensorMap), 0)
}
func ProgramStartTensorMapVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func ProgramAddRoutines(builder *flatbuffers.Builder, routines flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(5, flatbuffers.UOffsetT(routines), 0)
}
func ProgramStartRoutinesVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func ProgramAddSharedGmem(builder *flatbuffers.Builder, sharedGmem uint32) {
	builder.PrependUint32Slot(6, sharedGmem, 0)
}
func ProgramAddPrivateGmem(builder *flatbuffers.Builder, privateGmem uint32) {
	builder.PrependUint32Slot(7, privateGmem, 0)
}
func ProgramEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}
